{
  "authors": [
    {
      "name": "BioImgae.IO Team"
    }
  ],
  "cite": [
    {
      "text": "todo cite BioImageIO",
      "url": "https://bioimage.io"
    }
  ],
  "collection": [
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/2d9489cd-a4dd-4730-8a71-577d0fcd0f5c/cover.png"
      ],
      "description": "Mitochondria segmentation for electron microscopy.",
      "download_count": 4705,
      "id": "10.5281/zenodo.5874841",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-3d-unet-notebook"
      ],
      "name": "Mitochondria Segmentation for EM",
      "nickname": "kind-seashell",
      "nickname_icon": "\ud83d\udc1a",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5874841/5874842/rdf.yaml",
      "tags": [
        "3d",
        "electron-microscopy",
        "mitochondria",
        "instance-segmentation",
        "unet",
        "brain"
      ],
      "type": "model",
      "versions": [
        "5874842"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/a6d65a8b-4fed-453f-89f6-515a2a73a99e/cover.png"
      ],
      "description": "Neuron segmentation in EM, trained on the CREMI challenge data.",
      "download_count": 4667,
      "id": "10.5281/zenodo.5874741",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-3d-unet-notebook"
      ],
      "name": "Neuron Segmentation in EM (Membrane Prediction)",
      "nickname": "impartial-shrimp",
      "nickname_icon": "\ud83e\udd90",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5874741/5874742/rdf.yaml",
      "tags": [
        "unet",
        "neurons",
        "instance-segmentation",
        "electron-microscopy",
        "cremi",
        "connectomics",
        "3d",
        "affinity-prediction"
      ],
      "type": "model",
      "versions": [
        "5874742"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/a3d790f1-5203-4bd3-a975-d0fff38c0d97/cover.png"
      ],
      "description": "Nucleus segmentation for fluorescence microscopy",
      "download_count": 3355,
      "id": "10.5281/zenodo.5764892",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-2d-unet-notebook"
      ],
      "name": "NucleiSegmentationBoundaryModel",
      "nickname": "affable-shark",
      "nickname_icon": "\ud83e\udd88",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5764892/6322939/rdf.yaml",
      "tags": [
        "fluorescence-light-microscopy",
        "nuclei",
        "instance-segmentation",
        "unet",
        "2d"
      ],
      "type": "model",
      "versions": [
        "6322939"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/f2a796dc-27f5-43b8-aadb-981898f39b87/cover.png"
      ],
      "description": "Cell segmentation for phase-contrast microscopy.",
      "download_count": 3342,
      "id": "10.5281/zenodo.5869899",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-2d-unet-notebook",
        "ilastik/live-cell-boundary-model"
      ],
      "name": "LiveCellSegmentationBoundaryModel",
      "nickname": "hiding-tiger",
      "nickname_icon": "\ud83d\udc05",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5869899/6321179/rdf.yaml",
      "tags": [
        "2d",
        "transmission-light-microscopy",
        "label-free",
        "cells",
        "instance-segmentation",
        "unet"
      ],
      "type": "model",
      "versions": [
        "6321179",
        "5869900"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape; @constantinpape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/9a4c6150-10d1-4c82-9305-8ac21bc435b5/cover.png"
      ],
      "description": "Cell segmentation in EM of platynereis.",
      "download_count": 3067,
      "id": "10.5281/zenodo.6028280",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-3d-unet-notebook"
      ],
      "name": "PlatynereisEMcellsSegmentationBoundaryModel",
      "nickname": "willing-hedgehog",
      "nickname_icon": "\ud83e\udd94",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6028280/6028281/rdf.yaml",
      "tags": [
        "unet",
        "cells",
        "instance-segmentation",
        "electron-microscopy",
        "platynereis"
      ],
      "type": "model",
      "versions": [
        "6028281"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape; @constantinpape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/334f9dd9-ae1e-46e2-9a6a-5445758c4e9c/cover.png"
      ],
      "description": "{organelle} segmentation in EM of platynereis.",
      "download_count": 2718,
      "id": "10.5281/zenodo.6028097",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-3d-unet-notebook"
      ],
      "name": "PlatynereisEMnucleiSegmentationBoundaryModel",
      "nickname": "organized-badger",
      "nickname_icon": "\ud83e\udda1",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6028097/6028098/rdf.yaml",
      "tags": [
        "unet",
        "nuclei",
        "instance-segmentation",
        "electron-microscopy",
        "platynereis",
        "affinity-prediction"
      ],
      "type": "model",
      "versions": [
        "6028098"
      ]
    },
    {
      "authors": [
        {
          "name": "Hao Xu"
        },
        {
          "name": "Wei Ouyang"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/a24a1e8a-cdc5-4b56-b9c3-0b82417e74a5/hpaseg-cover.png"
      ],
      "description": "Cell segmentation model for segmenting images from the Human Protein Atlas",
      "download_count": 2126,
      "id": "10.5281/zenodo.6200635",
      "license": "CC-BY-4.0",
      "links": [
        "imjoy/BioImageIO-Packager",
        "imjoy/HPA-Single-Cell",
        "deepimagej/deepimagej"
      ],
      "name": "HPA Cell Segmentation (DPNUnet)",
      "nickname": "loyal-parrot",
      "nickname_icon": "\ud83e\udd9c",
      "owners": [
        47882
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6200635/6200636/rdf.yaml",
      "tags": [
        "nucleus-segmentation"
      ],
      "type": "model",
      "versions": [
        "6200636"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "Ikerbasque - EHU/UPV",
          "name": "Ignacio Arganda-Carreras"
        },
        {
          "affiliation": "EPFL, UC3M",
          "name": "DeepImageJ"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/436a4ace-0b71-4bee-bf08-b0c197350a4c/input.png",
        "https://zenodo.org/api/files/436a4ace-0b71-4bee-bf08-b0c197350a4c/output.png"
      ],
      "description": "DeepImageJ compatible U-Net trained to segment phase contrast microscopy images of pancreatic stem cells on a 2D polystyrene substrate.",
      "download_count": 1884,
      "id": "10.5281/zenodo.5914248",
      "license": "BSD-2-Clause",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "Pancreatic Phase Contrast Cell Segmentation (U-Net)",
      "nickname": "discreet-rooster",
      "nickname_icon": "\ud83d\udc13",
      "owners": [
        147356
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5914248/5914249/rdf.yaml",
      "tags": [
        "deepimagej",
        "pancreatic-stem-cells",
        "segmentation",
        "phase-contrast",
        "unet",
        "neubias",
        "cell-tracking-challenge",
        "2d",
        "tensorflow"
      ],
      "type": "model",
      "versions": [
        "5914249"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "UC3M, EPFL",
          "name": "DeepImageJ"
        },
        {
          "affiliation": "UCL, University of Turku and \u00c5bo Akademi University",
          "name": "ZeroCostDL4Mic"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/eb8f4259-001c-4989-b8ea-d2997918599d/input.png",
        "https://zenodo.org/api/files/eb8f4259-001c-4989-b8ea-d2997918599d/output.png"
      ],
      "description": "A 3D U-net to predict cell membranes in plant tissues, trained on volumes of Arabidopsis thaliana ovules acquired on a confocal microscope.",
      "download_count": 1712,
      "id": "10.5281/zenodo.5749843",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager",
        "ilastik/ilastik",
        "deepimagej/deepimagej"
      ],
      "name": "Cell Segmentation from Membrane Staining for Plant Tissues",
      "nickname": "humorous-owl",
      "nickname_icon": "\ud83e\udd89",
      "owners": [
        252845
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5749843/5888237/rdf.yaml",
      "tags": [
        "zerocostdl4mic",
        "deepimagej",
        "segmentation",
        "3d",
        "unet",
        "fluorescence-light-microscopy",
        "cell-membrane",
        "plant",
        "arabidopsis",
        "tensorflow"
      ],
      "type": "model",
      "versions": [
        "5888237",
        "5877226"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/be41e515-ce79-48f5-a482-35e1f11701c2/cover.png"
      ],
      "description": "Cell segmentation for immunofluorescence microscopy.",
      "download_count": 1530,
      "id": "10.5281/zenodo.5847355",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-2d-unet-notebook"
      ],
      "name": "CovidIFCellSegmentationBoundaryModel",
      "nickname": "powerful-chipmunk",
      "nickname_icon": "\ud83d\udc3f",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5847355/6322908/rdf.yaml",
      "tags": [
        "unet",
        "cells",
        "transmission-light-microscopy",
        "covid19",
        "immunofluorescence",
        "instance-segmentation"
      ],
      "type": "model",
      "versions": [
        "6322908"
      ]
    },
    {
      "authors": [
        {
          "github_user": "uschmidt83",
          "name": "Uwe Schmidt"
        },
        {
          "github_user": "maweigert",
          "name": "Martin Weigert"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/9ae447ab-07e8-4f44-bc0a-b750d72fe478/stardist_logo.jpg",
        "https://zenodo.org/api/files/9ae447ab-07e8-4f44-bc0a-b750d72fe478/example_histo.jpg"
      ],
      "description": "StarDist - Object Detection with Star-convex Shapes",
      "download_count": 1435,
      "id": "10.5281/zenodo.6338614",
      "license": "BSD-3-Clause",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "name": "StarDist H&E Nuclei Segmentation",
      "nickname": "chatty-frog",
      "nickname_icon": "\ud83d\udc38",
      "owners": [
        313404
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6338614/6338615/rdf.yaml",
      "tags": [
        "whole-slide-imaging",
        "2d",
        "nuclei",
        "tensorflow",
        "unet",
        "instance-segmentation",
        "object-detection",
        "stardist"
      ],
      "type": "model",
      "versions": [
        "6338615"
      ]
    },
    {
      "authors": [
        {
          "github_user": "uschmidt83",
          "name": "Uwe Schmidt"
        },
        {
          "github_user": "maweigert",
          "name": "Martin Weigert"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/7ad06458-46e3-444b-b018-55a3c7a9fe27/stardist_logo.jpg",
        "https://zenodo.org/api/files/7ad06458-46e3-444b-b018-55a3c7a9fe27/example_fluo.jpg"
      ],
      "description": "StarDist - Object Detection with Star-convex Shapes",
      "download_count": 1252,
      "id": "10.5281/zenodo.6348084",
      "license": "BSD-3-Clause",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "name": "StarDist Fluorescence Nuclei Segmentation",
      "nickname": "fearless-crab",
      "nickname_icon": "\ud83e\udd80",
      "owners": [
        313404
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6348084/6348085/rdf.yaml",
      "tags": [
        "fluorescence-light-microscopy",
        "whole-slide-imaging",
        "other",
        "2d",
        "cells",
        "nuclei",
        "tensorflow",
        "fiji",
        "unet",
        "instance-segmentation",
        "object-detection",
        "stardist"
      ],
      "type": "model",
      "versions": [
        "6348085"
      ]
    },
    {
      "authors": [
        {
          "name": "Hao Xu"
        },
        {
          "name": "Wei Ouyang"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/9f580ca7-5f85-41ac-be2b-201172ed09b3/hpaseg-cover.png"
      ],
      "description": "Nuclei segmentation model for segmenting images from the Human Protein Atlas",
      "download_count": 1166,
      "id": "10.5281/zenodo.6200999",
      "license": "CC-BY-4.0",
      "links": [
        "imjoy/BioImageIO-Packager",
        "imjoy/HPA-Single-Cell",
        "deepimagej/deepimagej"
      ],
      "name": "HPA Nucleus Segmentation (DPNUnet)",
      "nickname": "conscientious-seashell",
      "nickname_icon": "\ud83d\udc1a",
      "owners": [
        47882
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6200999/6224243/rdf.yaml",
      "tags": [
        "nucleus-segmentation"
      ],
      "type": "model",
      "versions": [
        "6224243"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "",
          "name": "ZeroCostDL4Mic team"
        },
        {
          "name": "Constantin Pape"
        },
        {
          "name": "DeepImageJ team"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/5a9cfb56-3a5d-4796-986d-8f46b7987b92/cover.png"
      ],
      "description": "2D UNet trained using ZeroCostDL4Mic notebooks on data from ISBI Challenge for neuron segmentation in Transmission Electron Microscopy images.",
      "download_count": 1148,
      "id": "10.5281/zenodo.5817052",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager",
        "zero/notebook_u-net_2d_zerocostdl4mic_deepimagej",
        "deepimagej/deepimagej"
      ],
      "name": "Neuron Segmentation in 2D EM (Membrane)",
      "nickname": "creative-panda",
      "nickname_icon": "\ud83d\udc3c",
      "owners": [
        271523
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5817052/5906839/rdf.yaml",
      "tags": [
        "zerocostdl4mic",
        "deepimagej",
        "segmentation",
        "electron-microscopy",
        "unet",
        "isbi2012-challenge",
        "neurons",
        "brain",
        "boundary-segmentation",
        "2d"
      ],
      "type": "model",
      "versions": [
        "5906839",
        "5850574"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape; @constantinpape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/573e9a49-d156-46ea-838e-55ec9ebe9e00/cover.png"
      ],
      "description": "affinity-model",
      "download_count": 1130,
      "id": "10.5281/zenodo.6079314",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-2d-unet-notebook",
        "ilastik/mws-segmentation"
      ],
      "name": "EpitheliaAffinityModel",
      "nickname": "wild-whale",
      "nickname_icon": "\ud83d\udc33",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6079314/6385590/rdf.yaml",
      "tags": [
        "u-net",
        "segmentation"
      ],
      "type": "model",
      "versions": [
        "6385590",
        "6079315"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/647f8e3d-3f05-4e3d-a43e-e72717a076a0/cover.png"
      ],
      "description": "Perform leaf segmentation in light microscopy images of Arabidopsis",
      "download_count": 1087,
      "id": "10.5281/zenodo.6348728",
      "license": "MIT",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "name": "Arabidopsis Leaf Segmentation",
      "nickname": "non-judgemental-eagle",
      "nickname_icon": "\ud83e\udd85",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6348728/6348729/rdf.yaml",
      "tags": [
        "zerocostdl4mic",
        "deepimagej",
        "segmentation",
        "unet"
      ],
      "type": "model",
      "versions": [
        "6348729"
      ]
    },
    {
      "authors": [
        {
          "name": "Shubin Dai"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/91895c21-4e8e-4cd0-98c3-1fae496b6068/bestfitting-densenet-diagram.png"
      ],
      "description": "The winning model of HPA image classification 2019 by Bestfitting",
      "download_count": 1040,
      "id": "10.5281/zenodo.5910163",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "HPA Bestfitting Densenet",
      "nickname": "polite-pig",
      "nickname_icon": "\ud83d\udc16",
      "owners": [
        47882
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5910163/5942853/rdf.yaml",
      "tags": [
        "classification",
        "densenet-121",
        "hpa",
        "onnx",
        "cells",
        "protein-localization"
      ],
      "type": "model",
      "versions": [
        "5942853"
      ]
    },
    {
      "authors": [
        {
          "name": "Lorenzo Cerrone"
        },
        {
          "name": "Adrian Wolny"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/990c06ad-189d-4cfa-8168-46bb2858a634/raw.png",
        "https://zenodo.org/api/files/990c06ad-189d-4cfa-8168-46bb2858a634/pred.png"
      ],
      "description": "A 2D U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Trained on z-slices of 3D confocal images.",
      "download_count": 1034,
      "id": "10.5281/zenodo.6334383",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "2D UNet Arabidopsis Ovules",
      "nickname": "pioneering-rhino",
      "nickname_icon": "\ud83e\udd8f",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6334383/6346500/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "2d",
        "semantic-segmentation",
        "arabidopsis",
        "ovules",
        "cell-membrane",
        "plant",
        "tissue",
        "fluorescence-light-microscopy",
        "pytorch"
      ],
      "type": "model",
      "versions": [
        "6346500",
        "6334384"
      ]
    },
    {
      "authors": [
        {
          "name": "Shubin Dai"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/c8028ef3-de08-459c-b88a-2f0bfd11485b/diagram-of-InceptionV3.png"
      ],
      "description": "The winning model of HPA image classification 2021 by Bestfitting",
      "download_count": 1026,
      "id": "10.5281/zenodo.5910854",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager",
        "imjoy/HPA-Single-Cell"
      ],
      "name": "HPA Bestfitting InceptionV3",
      "nickname": "straightforward-crocodile",
      "nickname_icon": "\ud83d\udc0a",
      "owners": [
        47882
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.5910854/5911832/rdf.yaml",
      "tags": [
        "classification",
        "inception-v3",
        "hpa",
        "onnx",
        "cells",
        "protein-localization"
      ],
      "type": "model",
      "versions": [
        "5911832"
      ]
    },
    {
      "authors": [
        {
          "name": "Adrian Wolny"
        },
        {
          "name": "Lorenzo Cerrone"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/6955b0c0-b211-42a1-8251-0e3d82f612d5/raw.png",
        "https://zenodo.org/api/files/6955b0c0-b211-42a1-8251-0e3d82f612d5/pred.png"
      ],
      "description": "A 3D U-Net trained to predict the cell boundaries in lightsheet stacks of Arabidopsis Lateral Root Primordia. (0.25x0.1625x0.1625) microns ZYX",
      "download_count": 903,
      "id": "10.5281/zenodo.6334777",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "3D UNet Lateral Root Primordia Cells",
      "nickname": "thoughtful-turtle",
      "nickname_icon": "\ud83d\udc22",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6334777/6346524/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "3d",
        "semantic-segmentation",
        "arabidopsis",
        "lateral-root",
        "cell-membrane",
        "plant",
        "tissue",
        "light-sheet-fluorescence-microscopy",
        "pytorch",
        "plantseg"
      ],
      "type": "model",
      "versions": [
        "6346524",
        "6334778"
      ]
    },
    {
      "authors": [
        {
          "name": "Lorenzo Cerrone"
        },
        {
          "name": "Adrian Wolny"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/9c2e422f-08fd-4692-bcf9-41e1a74e193d/raw.png",
        "https://zenodo.org/api/files/9c2e422f-08fd-4692-bcf9-41e1a74e193d/pred.png"
      ],
      "description": "3D Unet trained on confocal images of Arabidopsis thaliana apical stem cell: https://www.repository.cam.ac.uk/handle/1810/262530. Voxel size: [0.25, 0.25, 0.25]",
      "download_count": 902,
      "id": "10.5281/zenodo.6346511",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "3D UNet Arabidopsis Apical Stem Cells",
      "nickname": "emotional-cricket",
      "nickname_icon": "\ud83e\udd97",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6346511/6346512/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "3d",
        "semantic-segmentation",
        "arabidopsis",
        "stem-cells",
        "cell-membrane",
        "plant",
        "tissue",
        "fluorescence-light-microscopy",
        "pytorch"
      ],
      "type": "model",
      "versions": [
        "6346512"
      ]
    },
    {
      "authors": [
        {
          "name": "Adrian Wolny"
        },
        {
          "name": "Lorenzo Cerrone"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/9a608180-9f71-43d9-9242-b4e0a4aec21d/ilastik_raw.png",
        "https://zenodo.org/api/files/9a608180-9f71-43d9-9242-b4e0a4aec21d/ilastik_sneak.png",
        "https://zenodo.org/api/files/9a608180-9f71-43d9-9242-b4e0a4aec21d/ilastik_pred.png"
      ],
      "description": "A 3d U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Voxel size: (0.235, 0.150, 0.150) microns ZYX",
      "download_count": 718,
      "id": "10.5281/zenodo.6334583",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "3D UNet Arabidopsis Ovules",
      "nickname": "passionate-t-rex",
      "nickname_icon": "\ud83e\udd96",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6334583/6346519/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "3d",
        "semantic-segmentation",
        "arabidopsis",
        "ovules",
        "cell-membrane",
        "plant",
        "tissue",
        "fluorescence-light-microscopy",
        "pytorch"
      ],
      "type": "model",
      "versions": [
        "6346519",
        "6334584"
      ]
    },
    {
      "authors": [
        {
          "name": "Lorenzo Cerrone"
        },
        {
          "name": "Adrian Wolny"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/4a69ddca-3874-4469-b11d-b9ed626d197f/raw.png",
        "https://zenodo.org/api/files/4a69ddca-3874-4469-b11d-b9ed626d197f/pred.png"
      ],
      "description": "2D Unet trained on z-slices of confocal images of Arabidopsis thaliana apical stem cells. Trained on z-slices of 3D confocal images. Voxel size: [0.25, 0.25, 0.25]",
      "download_count": 706,
      "id": "10.5281/zenodo.6334881",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "2D UNet Arabidopsis Apical Stem Cells",
      "nickname": "laid-back-lobster",
      "nickname_icon": "\ud83e\udd9e",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6334881/6346477/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "2d",
        "semantic-segmentation",
        "arabidopsis",
        "stem-cells",
        "cell-membrane",
        "plant",
        "tissue",
        "fluorescence-light-microscopy",
        "pytorch"
      ],
      "type": "model",
      "versions": [
        "6346477",
        "6334882"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/a7eb8d94-9217-4276-8b0d-ff88e1ac78c7/cover.png"
      ],
      "description": "Segmentation of mitochondria in EM images.",
      "download_count": 632,
      "id": "10.5281/zenodo.6406803",
      "license": "CC-BY-4.0",
      "links": [
        "deepimagej/deepimagej",
        "ilastik/ilastik",
        "imjoy/BioImageIO-Packager",
        "ilastik/torch-em-2d-unet-notebook"
      ],
      "name": "MitchondriaEMSegmentation2D",
      "nickname": "shivering-raccoon",
      "nickname_icon": "\ud83e\udd9d",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6406803/6406804/rdf.yaml",
      "tags": [
        "unet",
        "mitochondria",
        "electron-microscopy",
        "instance-segmentation",
        "2d"
      ],
      "type": "model",
      "versions": [
        "6406804"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EMBL Heidelberg",
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/73fe6e10-5600-44ac-b8ab-f8c38568a529/cover.png"
      ],
      "description": "Prediction Enhancer for segmenting mitochondria in EM images.",
      "download_count": 625,
      "id": "10.5281/zenodo.6406756",
      "license": "CC-BY-4.0",
      "links": [
        "ilastik/ilastik",
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "name": "EnhancerMitochondriaEM2D",
      "nickname": "hiding-blowfish",
      "nickname_icon": "\ud83d\udc21",
      "owners": [
        77626
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6406756/6406757/rdf.yaml",
      "tags": [
        "unet",
        "mitochondria",
        "electron-microscopy",
        "instance-segmentation",
        "2d"
      ],
      "type": "model",
      "versions": [
        "6406757"
      ]
    },
    {
      "authors": [
        {
          "name": "A. Wolny"
        },
        {
          "name": "V. Bondarenko"
        }
      ],
      "covers": [
        "https://zenodo.org/api/files/87d721be-2c22-4b0c-b6e0-0aed3b4bdc33/raw.png",
        "https://zenodo.org/api/files/87d721be-2c22-4b0c-b6e0-0aed3b4bdc33/pred.png"
      ],
      "description": "A 3D U-Net trained to predict the cell boundaries in live light sheet images of developing mouse embryo. Voxel size: 0.2\u00d70.2\u00d71.0 \u00b5m^3",
      "download_count": 496,
      "id": "10.5281/zenodo.6384845",
      "license": "MIT",
      "links": [
        "imjoy/BioImageIO-Packager"
      ],
      "name": "3D UNet Mouse Embryo Live",
      "nickname": "powerful-fish",
      "nickname_icon": "\ud83d\udc1f",
      "owners": [
        66700
      ],
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/10.5281/zenodo.6384845/6384846/rdf.yaml",
      "tags": [
        "plantseg",
        "unet",
        "3d",
        "semantic-segmentation",
        "mouse-embryo",
        "cell-membrane",
        "animal",
        "tissue",
        "light-sheet-microscopy",
        "pytorch",
        "live"
      ],
      "type": "model",
      "versions": [
        "6384846"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "Universidad Carlos III de Madrid",
          "name": "Estibaliz G\u00f3mez-de-Mariscal"
        },
        {
          "affiliation": "Masaryk University",
          "name": "Martin Ma\u0161ka"
        },
        {
          "affiliation": "Masaryk University",
          "name": "Anna Kotrbov\u00e1"
        },
        {
          "affiliation": "Masaryk University",
          "name": "Vendula Posp\u00edchalov\u00e1"
        },
        {
          "affiliation": "Masaryk University",
          "name": "Pavel Matula"
        },
        {
          "affiliation": "Universidad Carlos III de Madrid",
          "name": "Arrate Mu\u00f1oz-Barrutia"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/BIIG-UC3M/FRU-Net-TEM-segmentation/blob/main/FRUnet_TEM_Exosomes_sEV.ipynb"
        }
      ],
      "covers": [
        "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-019-49431-3/MediaObjects/41598_2019_49431_Fig1_HTML.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/frunet_sev.jpg"
      ],
      "description": "Ready to use notebook for the segmentation of small extrcaellular vesicles in transmission electron microscopy (TEM) images. The notebook is optimized to use it in Google Colaboratory. It will download the original code and dataset, and make the inference connecting with Google's GPU.",
      "download_count": 1,
      "id": "deepimagej/EVsTEMsegmentationFRUNet",
      "links": [
        "deepimagej/FRUNet2DsEVSegmentation"
      ],
      "name": "Small extracellular vesicle instance segmentation (FRU-Net)",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/EVsTEMsegmentationFRUNet/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/BIIG-UC3M/FRU-Net-TEM-segmentation/master/FRUnet_TEM_Exosomes_sEV.ipynb",
      "tags": [
        "extracellular-vesicles",
        "segmentation",
        "TEM",
        "notebook",
        "model-inference",
        "google-colab",
        "workflow",
        "pipeline"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EPFL, UC3M",
          "name": "DeepImageJ"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg1.jpg",
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg2.jpg",
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg3.jpg"
      ],
      "description": "Labelled images for instance segmentation of cell nuclei in digital pathology datasets (MoNuSeg 2018 Challenge).",
      "download_count": 1,
      "id": "deepimagej/MoNuSeg_digital_pathology_miccai2018",
      "name": "Multi-Organ Nucleus Segmentation Challenge - MICCAI 2018",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/MoNuSeg_digital_pathology_miccai2018/latest/rdf.yaml",
      "source": "https://monuseg.grand-challenge.org/Data/",
      "tags": [
        "StarDist",
        "segmentation",
        "pathology",
        "H&E",
        "histology",
        "2D",
        "nuclei segmentation",
        "digital pathology"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [],
      "badges": [],
      "covers": [],
      "description": "Export BioImage.IO model packages for deepImageJ from a model description file",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "id": "deepimagej/deepimagej",
      "name": "deepimagej",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/deepimagej/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/src/deepimagej-app.imjoy.html",
      "tags": [
        "software",
        "bioengine"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EPFL, UC3M",
          "name": "DeepImageJ"
        }
      ],
      "description": "DeepImageJ is a user-friendly plugin that enables the use of pre-trained deep learning models in ImageJ and Fiji.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "id": "deepimagej/deepimagej-web",
      "name": "DeepImageJ",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/deepimagej-web/latest/rdf.yaml",
      "source": "https://deepimagej.github.io/deepimagej/index.html",
      "tags": [
        "deepimagej",
        "software"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EPFL, UC3M",
          "name": "DeepImageJ"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/workflows/smlm_deepstorm/cover.png"
      ],
      "description": "Single molecule localization microscopy (SMLM) processing using deepImageJ and ThunderSTORM in an ImageJ macro.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm",
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "id": "deepimagej/smlm-deepimagej",
      "name": "SMLM-superresolution",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/smlm-deepimagej/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm",
      "tags": [
        "deepimagej",
        "smlm",
        "macro",
        "deepstorm",
        "thunderstorm",
        "workflow",
        "pipeline",
        "superresolution"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "affiliation": "EPFL, UC3M",
          "name": "Ignacio Arganda-Carreras"
        },
        {
          "affiliation": "EPFL, UC3M",
          "name": "DeepImageJ"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/deepimagej/models/blob/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/notebook_intro.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/usecase.png"
      ],
      "description": "Easy example to define a 2D U-Net for segmentation with Keras and import it into DeepImageJ format",
      "download_count": 1,
      "id": "deepimagej/unet-pancreaticcellsegmentation",
      "links": [
        "deepimagej/UNet2DPancreaticSegmentation"
      ],
      "name": "2D U-Net for binary segmentation",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/deepimagej/unet-pancreaticcellsegmentation/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb",
      "tags": [
        "unet",
        "segmentation",
        "deepimagej",
        "notebook",
        "training",
        "cell-segmentation"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "badges": [],
      "covers": [
        "https://imjoy-team.github.io/imjoy-plugins/hpa-classification/hpa-classification-cover.gif"
      ],
      "description": "Resources for BioImgage.IO curated by the the cellprofiling group at HPA.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
      "id": "hpa/HPA-Classification",
      "name": "HPA Collection",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/hpa/HPA-Classification/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/imjoy-team/imjoy-plugins/master/repository/HPA-Classification.imjoy.html",
      "tags": [
        "hpa",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/covid-if-cover0.jpg",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/covid-if-cover1.jpg",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/covid-if-cover2.jpg"
      ],
      "description": "Training data for cell and nucleus segmentation as well as infection classification in IF data of Covid-19 infected cells.",
      "download_count": 1,
      "id": "ilastik/covid_if_training_data",
      "license": "CC-BY-4.0",
      "name": "Covid-IF Training Data",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/covid_if_training_data/latest/rdf.yaml",
      "source": "https://zenodo.org/record/5092850",
      "tags": [
        "high-content-imaging",
        "fluorescence-light-microscopy",
        "2D",
        "cells",
        "nuclei",
        "covid19",
        "semantic-segmentation",
        "instance-segmentation"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/cremi-cover0.png",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/cremi-cover1.png",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/cremi-cover2.png"
      ],
      "description": "Training data from the challenge on 3d EM segmentation on neuronal processes.",
      "download_count": 1,
      "id": "ilastik/cremi_training_data",
      "name": "CREMI: MICCAI Challenge on Circuit Reconstruction from Electron Microscopy Images",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/cremi_training_data/latest/rdf.yaml",
      "source": "https://cremi.org/",
      "tags": [
        "electron-microscopy",
        "brain",
        "neurons",
        "instance-segmentation",
        "cremi-challenge",
        "3D"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "ilastik Team"
        }
      ],
      "badges": [],
      "covers": [],
      "description": "the interactive learning and segmentation toolkit",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/master/image/ilastik-fist-icon.png",
      "id": "ilastik/ilastik",
      "name": "ilastik",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/ilastik/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/src/ilastik-app.imjoy.html",
      "tags": [
        "ilastik",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/isbi2012-cover0.jpg",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/isbi2012-cover1.png"
      ],
      "description": "Training data from challenge on 2d EM segmentation of neuronal processes.",
      "download_count": 1,
      "id": "ilastik/isbi2012_neuron_segmentation_challenge",
      "name": "ISBI Challenge: Segmentation of neuronal structures in EM stacks",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/isbi2012_neuron_segmentation_challenge/latest/rdf.yaml",
      "source": "https://oc.embl.de/index.php/s/sXJzYVK0xEgowOz/download",
      "tags": [
        "electron-microscopy",
        "brain",
        "neurons",
        "instance-segmentation",
        "2D",
        "isbi2012-challenge"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "ImJoy Team"
        },
        {
          "name": "ilastik Team"
        }
      ],
      "badges": [],
      "covers": [],
      "description": "Run the live cell boundary model via the BioEngine",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/07147313b07f6842f0b9890ee7a79e47c44258e5/image/circular-play-button.png",
      "id": "ilastik/live-cell-boundary-model",
      "name": "Live cell boundary model preview",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/live-cell-boundary-model/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/src/live-cell-boundary-preview.imjoy.html",
      "tags": [
        "ilastik",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/livecell-cover0.jpg"
      ],
      "description": "LIVECell\u2014A large-scale dataset for label-free live cell segmentation",
      "download_count": 1,
      "id": "ilastik/livecell_dataset",
      "license": "CC-BY-NC-4.0",
      "name": "LIVECell",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/livecell_dataset/latest/rdf.yaml",
      "source": "https://sartorius-research.github.io/LIVECell/",
      "tags": [
        "2D",
        "transmission-light-microscopy",
        "label-free",
        "cells",
        "instance-segmentation"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/mitoem-cover0.jpg",
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/mitoem-cover1.png"
      ],
      "description": "Training data for mitochondria segmentation in 3d EM.",
      "download_count": 1,
      "id": "ilastik/mitoem_segmentation_challenge",
      "name": "MitoEM Challenge: Large-scale 3D Mitochondria Instance Segmentation",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/mitoem_segmentation_challenge/latest/rdf.yaml",
      "source": "https://mitoem.grand-challenge.org/",
      "tags": [
        "mitochondria",
        "electron-microscopy",
        "3D",
        "mito-em-challenge",
        "instance-segmentation"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "badges": [],
      "covers": [],
      "description": "Segmentation plugin for models that predict pixel affinities",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/mws.png",
      "id": "ilastik/mws-segmentation",
      "name": "Mutex Watershed Plugin",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/mws-segmentation/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/src/mws-segmentation.imjoy.html",
      "tags": [
        "ilastik",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/plantseg_cover.jpg"
      ],
      "description": "Training data for cell segmentation in Arabidopsis ovules.",
      "download_count": 1,
      "id": "ilastik/plantseg_ovules",
      "license": "CC-BY-4.0",
      "name": "Arabidopsis Ovules Traning Data",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/plantseg_ovules/latest/rdf.yaml",
      "source": "https://osf.io/w38uf/",
      "tags": [
        "light-microscopy",
        "arabidopsis",
        "cells",
        "instance-segmentation",
        "3D"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/plantseg_cover.jpg"
      ],
      "description": "Training data for cell segmentation in Arabidopsis lateral root.",
      "download_count": 1,
      "id": "ilastik/plantseg_root",
      "license": "CC-BY-4.0",
      "name": "Arabidopsis Lateral Root Traning Data",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/plantseg_root/latest/rdf.yaml",
      "source": "https://osf.io/2rszy/",
      "tags": [
        "light-microscopy",
        "arabidopsis",
        "cells",
        "instance-segmentation",
        "3D"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/platy-cover0.png"
      ],
      "description": "Training data for EM segmentation of cellular membranes, nuclei, cuticle and cilia in Platynereis.",
      "download_count": 1,
      "id": "ilastik/platynereis_em_training_data",
      "license": "CC-BY-4.0",
      "name": "Platynereis EM Traning Data",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/platynereis_em_training_data/latest/rdf.yaml",
      "source": "https://doi.org/10.5281/zenodo.3675220",
      "tags": [
        "electron-microscopy",
        "platynereis",
        "cells",
        "cilia",
        "nuclei",
        "instance-segmentation",
        "3D"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/dataset_src/dsb-cover0.jpg"
      ],
      "description": "Subset of the nucleus segmentation training data from the 2018 Kaggle Data Science Bowl.",
      "download_count": 1,
      "id": "ilastik/stradist_dsb_training_data",
      "license": "CC0-1.0",
      "name": "DSB Nucleus Segmentation Training Data",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/stradist_dsb_training_data/latest/rdf.yaml",
      "source": "https://github.com/stardist/stardist/releases/download/0.1.0/dsb2018.zip",
      "tags": [
        "nuclei",
        "instance-segmentation",
        "fluorescence-light-microscopy",
        "dsb-challenge",
        "2D"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/constantinpape/torch-em/main/experiments/misc/targets.png"
      ],
      "description": "Train a 2d UNet for semgentation tasks",
      "download_count": 1,
      "id": "ilastik/torch-em-2d-unet-notebook",
      "license": "CC-BY-4.0",
      "name": "2D UNet Training",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/torch-em-2d-unet-notebook/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/constantinpape/torch-em/main/experiments/2D-UNet-Training.ipynb",
      "tags": [
        "instance-segmentation",
        "semantic-segmentation",
        "u-net",
        "2d"
      ],
      "type": "notebook",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/constantinpape/torch-em/main/experiments/misc/targets.png"
      ],
      "description": "Train a 2d UNet for semgentation tasks",
      "download_count": 1,
      "id": "ilastik/torch-em-3d-unet-notebook",
      "license": "CC-BY-4.0",
      "name": "3D UNet Training",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/torch-em-3d-unet-notebook/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/constantinpape/torch-em/main/experiments/3D-UNet-Training.ipynb",
      "tags": [
        "instance-segmentation",
        "semantic-segmentation",
        "u-net",
        "3d"
      ],
      "type": "notebook",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Constantin Pape"
        }
      ],
      "covers": [
        "https://s3-eu-west-1.amazonaws.com/pfigshare-u-previews/1288336/preview.jpg"
      ],
      "description": "Training data for cell segmentation in Arabidopsis lateral root.",
      "download_count": 1,
      "id": "ilastik/vnc",
      "license": "CC-BY-4.0",
      "name": "Segmented anisotropic ssTEM dataset of neural tissue",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/ilastik/vnc/latest/rdf.yaml",
      "source": "https://github.com/unidesigner/groundtruth-drosophila-vnc",
      "tags": [
        "electron-microscopy",
        "drosophila",
        "neurons",
        "instance-segmentation"
      ],
      "type": "dataset",
      "versions": [
        "latest"
      ]
    },
    {
      "badges": [],
      "covers": [],
      "description": "Resources for BioImgage.IO curated by the ImJoy Team.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/asset/download-icon.png",
      "id": "imjoy/BioImageIO-Packager",
      "name": "BioImageIO-Packager",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/imjoy/BioImageIO-Packager/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/src/bioimageio-packager.imjoy.html",
      "tags": [
        "imjoy",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "badges": [],
      "covers": [],
      "description": "Resources for BioImgage.IO curated by the ImJoy Team.",
      "download_count": 1,
      "icon": "https://imjoy.io/static/img/imjoy-icon.png",
      "id": "imjoy/ImJoy",
      "name": "ImJoy",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/imjoy/ImJoy/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/src/imjoy-app.imjoy.html",
      "tags": [
        "imjoy",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "badges": [],
      "covers": [],
      "description": "Resources for BioImgage.IO curated by the ImJoy Team.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/imjoy-team/imagej.js/master/src/assets/icons/chrome/chrome-installprocess-128-128.png",
      "id": "imjoy/ImageJ.JS",
      "name": "ImJoy Collection",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/imjoy/ImageJ.JS/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/src/imagej-js.imjoy.html",
      "tags": [
        "imjoy",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "badges": [],
      "covers": [],
      "description": "Resources for BioImgage.IO curated by the ImJoy Team.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/hms-dbmi/vizarr/main/assets/logo.png",
      "id": "imjoy/vizarr",
      "name": "vizarr",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/imjoy/vizarr/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/src/vizarr.imjoy.html",
      "tags": [
        "imjoy",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [],
      "badges": [],
      "covers": [],
      "description": "Resources for BioImgage.IO curated by the ZeroCost4Mic team.",
      "download_count": 1,
      "icon": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/asset/preview-icon-small.png",
      "id": "zero/Notebook Preview",
      "name": "ZeroCost4Mic Collection",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook Preview/latest/rdf.yaml",
      "source": "https://raw.githubusercontent.com/bioimage-io/nbpreview/master/notebook-preview.imjoy.html",
      "tags": [
        "zero",
        "bioimage.io"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/augmentor_notebook.png"
      ],
      "description": "Artificially increase the size of your training dataset. Augmentor is a data augmentation library. Data augmentation can improve training progress by amplifying differences in the dataset. This can be useful if the available dataset is small since, in this case, it is possible that a network could quickly learn every example in the dataset (overfitting), without augmentation. Augmentation can be especially valuable when training dataset need to be manually labelled. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Augmentor_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "Augmentor - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Augmentor_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Augmentor",
        "Data Augmentation",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook_2.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/CARE2D_notebook_3.png"
      ],
      "description": "Supervised restoration of 2D images. CARE is a neural network capable of image restoration from corrupted bio-images, first published in 2018 by Weigert et al. in Nature Methods. The network allows image denoising and resolution improvement in 2D and 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_CARE_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_CARE_2D_ZeroCostDL4Mic",
        "zero/Dataset_Noisy_Nuclei_ZeroCostDL4Mic",
        "zero/Dataset_CARE_2D_coli_DeepBacs",
        "zero/Dataset_fnet_DeepBacs"
      ],
      "name": "CARE (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_CARE_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "CARE",
        "denoising",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_CARE_notebook.png"
      ],
      "description": "Supervised restoration of 3D images. CARE is a neural network capable of image restoration from corrupted bio-images, first published in 2018 by Weigert et al. in Nature Methods. The network allows image denoising and resolution improvement in 2D and 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_CARE_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_CARE_3D_ZeroCostDL4Mic"
      ],
      "name": "CARE (3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_CARE_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "CARE",
        "denoising",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_2.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_3.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_4.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_5.png"
      ],
      "description": "Instance segmentation of 2D and 3D images. Cellpose is a generalist algorithm for cellular segmentation.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Cellpose_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D",
        "zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic"
      ],
      "name": "Cellpose (2D and 3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Cellpose_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Cellpose",
        "Segmentation",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cycleGAN_notebook.png"
      ],
      "description": "Unpaired image-to-image translation of 2D images. CycleGAN is a method that can capture the characteristics of one image domain and figure out how these characteristics could be translated into another image domain, all in the absence of any paired training examples (ie transform a horse into zebra or apples into oranges). While CycleGAN can potentially be used for any type of image-to-image translation, we illustrate that it can be used to predict what a fluorescent label would look like when imaged using another imaging modalities. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_CycleGAN_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_CycleGAN_ZeroCostDL4Mic"
      ],
      "name": "CycleGAN (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_CycleGAN_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "CycleGAN",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Ainhoa Serrano, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DFCAN_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DFCAN_notebook.png"
      ],
      "description": "Super-resolution via super-pixelisation. Deep Fourier channel attention network (DFCAN) is a network created to transform low-resolution (LR) images to super-resolved (SR) images, published by Qiao, Chang and Li, Di and Guo, Yuting and Liu, Chong and Jiang, Tao and Dai, Qionghai and Li, Dong. The training is done using LR-SR image pairs, taking the LR images as input and obtaining an output as close to SR as posible.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DFCAN_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_DFCAN_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "DFCAN - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_DFCAN_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "DFCAN",
        "Super Resolution",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DrMIME_notebook.png"
      ],
      "description": "DRMIME is an network that can be used to register microscopy images (affine and perspective registration).",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_DRMIME_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "DRMIME - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_DRMIME_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "DRMIME",
        "image registration",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DecoNoising_notebook.png"
      ],
      "description": "Self-supervised denoising of 2D images. DecoNoising 2D is deep-learning method that can be used to denoise 2D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_DecoNoising_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_Noise2Void_2D_ZeroCostDL4Mic",
        "zero/Dataset_Noise2Void_2D_subtilis_DeepBacs",
        "zero/Dataset_Noisy_Nuclei_ZeroCostDL4Mic",
        "zero/Dataset_CARE_2D_coli_DeepBacs"
      ],
      "name": "DecoNoising (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_DecoNoising_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "DecoNoising",
        "denoising",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain Laine and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook_2.png"
      ],
      "description": "Single Molecule Localization Microscopy (SMLM) image reconstruction from high-density emitter data. Deep-STORM is a neural network capable of image reconstruction from high-density single-molecule localization microscopy (SMLM), first published in 2018 by Nehme et al. in Optica. This network allows image reconstruction of 2D super-resolution images, in a supervised training manner. The network is trained using simulated high-density SMLM data for which the ground-truth is available. These simulations are obtained from random distribution of single molecules in a field-of-view and therefore do not imprint structural priors during training. The network output a super-resolution image with increased pixel density (typically upsampling factor of 8 in each dimension). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_Deep-STORM_ZeroCostDL4Mic"
      ],
      "name": "Deep-STORM (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Deep-STORM",
        "labelling",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Estibaliz G\u00f3mez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/DeepSTORM_notebook_2.png"
      ],
      "description": "Single Molecule Localization Microscopy (SMLM) image reconstruction from high-density emitter data. Deep-STORM is a neural network capable of image reconstruction from high-density single-molecule localization microscopy (SMLM), first published in 2018 by Nehme et al. in Optica. This network allows image reconstruction of 2D super-resolution images, in a supervised training manner. The network is trained using simulated high-density SMLM data for which the ground-truth is available. These simulations are obtained from random distribution of single molecules in a field-of-view and therefore do not imprint structural priors during training. The network output a super-resolution image with increased pixel density (typically upsampling factor of 8 in each dimension). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ and ThunderSTORM plugin.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb",
      "id": "zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_Deep-STORM_ZeroCostDL4Mic"
      ],
      "name": "Deep-STORM (2D) - ZeroCostDL4Mic - DeepImageJ",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Deep-STORM",
        "DeepImageJ",
        "ZeroCostDL4Mic",
        "2D",
        "deepImageJ"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/Denoiseg_notebook.png"
      ],
      "description": "Joint denoising and binary segmentation of 2D images. DenoiSeg 2D is deep-learning method that can be used to jointly denoise and segment 2D microscopy images. The benefits of using DenoiSeg (compared to other Deep Learning-based segmentation methods) are more prononced when only a few annotated images are available. However, the denoising part requires many images to perform well. All the noisy images don't need to be labeled to train DenoiSeg. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_DenoiSeg_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "DenoiSeg (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_DenoiSeg_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "CycleGAN",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png"
      ],
      "description": "Object detection of 2D images. Detectron2 is an object detection network developed by Facebook AI Research, which identifies objects in images and draws bounding boxes around them.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Detectron2_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_YOLOv2_ZeroCostDL4Mic",
        "zero/Dataset_YOLOv2_coli_DeepBacs",
        "zero/Dataset_YOLOv2_antibiotic_DeepBacs"
      ],
      "name": "Detectron2 - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Detectron2_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Detectron2",
        "object detection",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Amin Rezaei, Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/EmbedSeg_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png"
      ],
      "description": "Instance segmentation of 2D images. EmbedSeg 2D is a deep-learning method that can be used to segment object from bioimages and was first published by Lalit et al. in 2021, on arXiv.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/EmbedSeg_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_EmbedSeg_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D",
        "zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic"
      ],
      "name": "EmbedSeg (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_EmbedSeg_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "EmbedSeg",
        "Segmentation",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain Laine, Wei Ouyang and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_2.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_3.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_4.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/cellpose_notebook_5.png"
      ],
      "description": "Interactive instance segmentation using Kaibu and Cellpose.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb",
      "id": "zero/Notebook_Interactive_Segmentation_Kaibu_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "Interactive Segmentation - Kaibu (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Interactive_Segmentation_Kaibu_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Cellpose",
        "Segmentation",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/maskRCNN_notebook.png"
      ],
      "description": "Instance segmentation of 2D images. MaskRCNN is a is an object detection and segmentation network, which identifies objects in images and draws bounding boxes around them.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_MaskRCNN_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "MaskRCNN - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_MaskRCNN_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "MaskRCNN",
        "object detection",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain Laine and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_2D_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V2D_notebook_3.png"
      ],
      "description": "self-supervised denoising of 2D images. Noise2Void 2D is deep-learning method that can be used to denoise 2D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Noise2Void_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_Noise2Void_2D_ZeroCostDL4Mic",
        "zero/Dataset_Noise2Void_2D_subtilis_DeepBacs",
        "zero/Dataset_Noisy_Nuclei_ZeroCostDL4Mic",
        "zero/Dataset_CARE_2D_coli_DeepBacs"
      ],
      "name": "Noise2Void (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Noise2Void_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Noise2Void",
        "denoising",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain Laine and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/N2V_3D_notebook_2.png"
      ],
      "description": "self-supervised denoising of 3D images. Noise2VOID 3D is deep-learning method that can be used to denoise 3D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Noise2Void_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_Noise2Void_3D_ZeroCostDL4Mic"
      ],
      "name": "Noise2VOID (3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Noise2Void_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Noise2Void",
        "denoising",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/QC_notebook.png"
      ],
      "description": "Error mapping and quality metrics estimation.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_Quality_Control_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "Quality Control - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_Quality_Control_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "Quality Control",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_CARE_notebook.png"
      ],
      "description": "Supervised restoration of 3D images. RCAN is a neural network capable of image restoration from corrupted bio-images. The network allows image denoising and resolution improvement in 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_RCAN_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_CARE_3D_ZeroCostDL4Mic"
      ],
      "name": "RCAN (3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_RCAN_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "3D-RCAN",
        "denoising",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Erlantz Calvo, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png"
      ],
      "description": "Object detection of 2D images. RetinaNet is a is an object detection network, which identifies objects in images and draws bounding boxes around them.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_RetinaNet_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_YOLOv2_ZeroCostDL4Mic",
        "zero/Dataset_YOLOv2_coli_DeepBacs",
        "zero/Dataset_YOLOv2_antibiotic_DeepBacs"
      ],
      "name": "RetinaNet - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_RetinaNet_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "RetinaNet",
        "object detection",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain F. Laine and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/SplineDist_overlay_cropped.png"
      ],
      "description": "Instance segmentation of 2D images. SplineDist is a neural network inspired by StarDist, capable of performing image instance segmentation. Unlike StarDist, SplineDist uses cubic splines to describe the contour of each object and therefore can potentially segment objects of any shapes. This version is only for 2D dataset. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_SplineDist_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D",
        "zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_2D_DeepBacs",
        "zero/Dataset_SplineDist_2D_DeepBacs"
      ],
      "name": "SplineDist (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_SplineDist_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "SplineDist",
        "segmentation",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png"
      ],
      "description": "2D instance segmentation of oval objects (ie nuclei). StarDist is a deep-learning method that can be used to segment cell nuclei in 2D (xy) single images or in stacks (xyz). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_StarDist_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D",
        "zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_2D_DeepBacs"
      ],
      "name": "StarDist (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_StarDist_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "StarDist",
        "segmentation",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Estibaliz G\u00f3mez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Stardist_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png"
      ],
      "description": "2D instance segmentation of oval objects (ie nuclei). StarDist is a deep-learning method that can be used to segment cell nuclei in 2D (xy) images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ and StarDist plugins for ImageJ.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb",
      "id": "zero/Notebook_StarDist_2D_ZeroCostDL4Mic_DeepImageJ",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_StarDist_2D_ZeroCostDL4Mic_2D",
        "zero/Dataset_StarDist_Fluo_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_brightfield2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_fluo2_ZeroCostDL4Mic",
        "zero/Dataset_StarDist_2D_DeepBacs"
      ],
      "name": "StarDist (2D) - ZeroCostDL4Mic - DeepImageJ",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_StarDist_2D_ZeroCostDL4Mic_DeepImageJ/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "StarDist",
        "segmentation",
        "ZeroCostDL4Mic",
        "2D",
        "deepimagej"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/StarDist_3D.png"
      ],
      "description": "3D instance segmentation of oval objects (ie nuclei). StarDist is a deep-learning method that can be used to segment cell nuclei in 3D (xyz) images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_StarDist_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "StarDist (3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_StarDist_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "StarDist",
        "segmentation",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Romain Laine and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Unet_notebook.png"
      ],
      "description": "2D binary segmentation. U-Net is an encoder-decoder architecture originally used for image segmentation. The first half of the U-Net architecture is a downsampling convolutional neural network which acts as a feature extractor from input images. The other half upsamples these results and restores an image by combining results from downsampling with the upsampled images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_U-Net_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_U-Net_2D_DeepBacs"
      ],
      "name": "U-Net (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_U-Net_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "U-Net",
        "segmentation",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Estibaliz G\u00f3mez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/2D_Unet_notebook.png"
      ],
      "description": "2D binary segmentation. U-Net is an encoder-decoder architecture originally used for image segmentation. The first half of the U-Net architecture is a downsampling convolutional neural network which acts as a feature extractor from input images. The other half upsamples these results and restores an image by combining results from downsampling with the upsampled images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb",
      "id": "zero/Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "U-Net (2D) - ZeroCostDL4Mic - DeepImageJ",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "U-Net",
        "segmentation",
        "ZeroCostDL4Mic",
        "2D",
        "deepimagej"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Estibaliz G\u00f3mez de Mariscal and the ZeroCostDL4Mic teams"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/UNet_Multilabel_example.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/UNet-multilabel-example-zoom.png"
      ],
      "description": "2D semantic segmentation. U-Net is an encoder-decoder architecture originally used for image segmentation. The first half of the U-Net architecture is a downsampling convolutional neural network which acts as a feature extractor from input images. The other half upsamples these results and restores an image by combining results from downsampling with the upsampled images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/U-Net_2D_Multilabel_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_U-Net_2D_multilabel_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_U-Net_2D_multilabel_DeepBacs"
      ],
      "name": "U-Net (2D) multilabel segmentation - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_U-Net_2D_multilabel_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "u-net",
        "segmentation",
        "semantic-segmentation",
        "multilabel",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Daniel Krentzel and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_Unet_notebook.png"
      ],
      "description": "3D binary segmentation. The 3D U-Net was first introduced by \u00c7i\u00e7ek et al for learning dense volumetric segmentations from sparsely annotated ground-truth data building upon the original U-Net architecture by Ronneberger et al. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_U-Net_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "U-Net (3D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_U-Net_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "U-Net",
        "segmentation",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Estibaliz G\u00f3mez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/3D_Unet_notebook.png"
      ],
      "description": "3D binary segmentation. The 3D U-Net was first introduced by \u00c7i\u00e7ek et al for learning dense volumetric segmentations from sparsely annotated ground-truth data building upon the original U-Net architecture by Ronneberger et al. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb",
      "id": "zero/Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ",
      "links": [
        "zero/Notebook Preview"
      ],
      "name": "U-Net (3D) - ZeroCostDL4Mic - DeepImageJ",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "U-Net",
        "segmentation",
        "ZeroCostDL4Mic",
        "3D",
        "deepimagej"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/yolo_notebook_2.png"
      ],
      "description": "Object detection of 2D images. YOLOv2 is an object detection network developed by Redmon & Farhadi, which identifies objects in images and draws bounding boxes around them.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_YOLOv2_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_YOLOv2_ZeroCostDL4Mic",
        "zero/Dataset_YOLOv2_coli_DeepBacs",
        "zero/Dataset_YOLOv2_antibiotic_DeepBacs"
      ],
      "name": "YOLOv2 - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_YOLOv2_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "YOLOv2",
        "object detection",
        "ZeroCostDL4Mic"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/fnet_notebook.png"
      ],
      "description": "Paired image-to-image translation of 2D images. Label-free Prediction (fnet) is a neural network used to infer the features of cellular structures from brightfield or EM images without coloured labels. The network is trained using paired training images from the same field of view, imaged in a label-free (e.g. brightfield) and labelled condition (e.g. fluorescent protein). When trained, this allows the user to identify certain structures from brightfield images alone. The performance of fnet may depend significantly on the structure at hand. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_fnet_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_fnet_DeepBacs"
      ],
      "name": "Label-free Prediction - fnet - (2D) ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_fnet_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "fnet",
        "labelling",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Lucas von Chamier and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/fnet_notebook.png"
      ],
      "description": "Paired image-to-image translation of 3D images. Label-free Prediction (fnet) is a neural network used to infer the features of cellular structures from brightfield or EM images without coloured labels. The network is trained using paired training images from the same field of view, imaged in a label-free (e.g. brightfield) and labelled condition (e.g. fluorescent protein). When trained, this allows the user to identify certain structures from brightfield images alone. The performance of fnet may depend significantly on the structure at hand. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_fnet_3D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_fnet_3D_ZeroCostDL4Mic"
      ],
      "name": "Label-free Prediction - fnet - (3D) ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_fnet_3D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "fnet",
        "labelling",
        "ZeroCostDL4Mic",
        "3D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    },
    {
      "authors": [
        {
          "name": "Guillaume Jacquemet and the ZeroCostDL4Mic Team"
        }
      ],
      "badges": [
        {
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "label": "Open in Colab",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb"
        }
      ],
      "covers": [
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/pix2pix_notebook_2.png",
        "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/BioimageModelZoo/Images/pix2pix_notebook.png"
      ],
      "description": "Paired image-to-image translation of 2D images. pix2pix is a deep-learning method that can be used to translate one type of images into another. While pix2pix can potentially be used for any type of image-to-image translation, we demonstrate that it can be used to predict a fluorescent image from another fluorescent image. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.",
      "download_count": 1,
      "download_url": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb",
      "id": "zero/Notebook_pix2pix_2D_ZeroCostDL4Mic",
      "links": [
        "zero/Notebook Preview",
        "zero/Dataset_pix2pix_ZeroCostDL4Mic"
      ],
      "name": "pix2pix (2D) - ZeroCostDL4Mic",
      "rdf_source": "https://bioimage-io.github.io/collection-bioimage-io/rdfs/zero/Notebook_pix2pix_2D_ZeroCostDL4Mic/latest/rdf.yaml",
      "tags": [
        "colab",
        "notebook",
        "pix2pix",
        "ZeroCostDL4Mic",
        "2D"
      ],
      "type": "application",
      "versions": [
        "latest"
      ]
    }
  ],
  "config": {
    "background_image": "static/img/zoo-background.svg",
    "default_type": "model",
    "explore_button_text": "Start Exploring",
    "n_resource_versions": {
      "application": 94,
      "dataset": 22,
      "model": 60,
      "notebook": 4
    },
    "n_resources": {
      "application": 47,
      "dataset": 11,
      "model": 26,
      "notebook": 2
    },
    "partners": [
      {
        "background_image": "static/img/zoo-background.svg",
        "default_type": "application",
        "explore_button_text": "Start Exploring",
        "icon": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png",
        "id": "zero",
        "logo": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png",
        "name": "ZeroCostDL4Mic",
        "resource_types": [
          "model",
          "application",
          "dataset"
        ],
        "source": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/manifest.bioimage.io.yaml",
        "splash_feature_list": [],
        "splash_subtitle": "A Google Colab based no-cost toolbox to explore Deep-Learning in Microscopy",
        "splash_title": "ZeroCostDL4Mic",
        "tags": [
          "ZeroCostDL4Mic"
        ],
        "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master",
        "version": "1.7.1"
      },
      {
        "background_image": "static/img/zoo-background.svg",
        "explore_button_text": "Start Exploring",
        "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
        "id": "deepimagej",
        "logo": "https://raw.githubusercontent.com/deepimagej/models/master/logos/logo.png",
        "name": "DeepImageJ",
        "resource_types": [
          "model",
          "notebook",
          "application"
        ],
        "source": "https://raw.githubusercontent.com/deepimagej/models/master/manifest.bioimage.io.yaml",
        "splash_feature_list": null,
        "splash_subtitle": "A user-friendly plugin to run deep learning models in ImageJ",
        "splash_title": "deepImageJ",
        "tags": [
          "deepimagej"
        ],
        "test_summaries": {
          "deploy_branch": "gh-pages",
          "deploy_folder": "test_summaries",
          "repository": "deepimagej/models",
          "workflow": "test_bioimageio_resources.yaml",
          "workflow_ref": "refs/heads/master"
        },
        "url_root": "https://raw.githubusercontent.com/deepimagej/models/master"
      },
      {
        "background_image": "static/img/zoo-background.svg",
        "explore_button_text": "Start Exploring",
        "icon": "https://fiji.sc/site/logo.png",
        "id": "fiji",
        "logo": "https://fiji.sc/site/logo.png",
        "name": "Fiji",
        "resource_types": [
          "model",
          "notebook"
        ],
        "source": "https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/manifest.bioimage.io.yaml",
        "splash_feature_list": [],
        "splash_subtitle": "Fiji is just ImageJ",
        "splash_title": "Fiji",
        "tags": [
          "fiji"
        ],
        "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master"
      },
      {
        "background_image": "static/img/zoo-background.svg",
        "default_type": "application",
        "explore_button_text": "Start Exploring",
        "icon": "https://imjoy.io/static/img/imjoy-icon.svg",
        "id": "imjoy",
        "logo": "https://imjoy.io/static/img/imjoy-icon.svg",
        "name": "ImJoy",
        "resource_types": [
          "notebook",
          "application"
        ],
        "source": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master/manifest.bioimage.io.yaml",
        "splash_feature_list": [
          "Minimal and flexible plugin powered web application",
          "Server-less progressive web application with offline support",
          "Rich and interactive user interface powered by web technologies"
        ],
        "splash_subtitle": "Deep Learning Made Easy!",
        "splash_title": "ImJoy",
        "tags": [
          "imjoy"
        ],
        "url_root": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master"
      },
      {
        "background_image": "static/img/zoo-background.svg",
        "default_type": "model",
        "explore_button_text": "Start Exploring",
        "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/ilastik-fist-icon.png",
        "id": "ilastik",
        "logo": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/ilastik-fist-icon.png",
        "name": "ilastik",
        "resource_types": [
          "application"
        ],
        "source": "https://raw.githubusercontent.com/ilastik/bioimage-io-resources/main/collection.yaml",
        "splash_feature_list": null,
        "splash_subtitle": "the interactive learning and segmentation toolkit",
        "splash_title": "ilastik",
        "tags": [
          "ilastik"
        ],
        "test_summaries": {
          "deploy_branch": "gh-pages",
          "deploy_folder": "test_summaries",
          "repository": "ilastik/bioimage-io-resources",
          "workflow": "test_bioimageio_resources.yaml",
          "workflow_ref": "refs/heads/main"
        },
        "url_root": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main"
      },
      {
        "about_url": "https://www.proteinatlas.org/",
        "background_image": "static/img/zoo-background.svg",
        "default_type": "model",
        "explore_button_text": "Start Exploring",
        "icon": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
        "id": "hpa",
        "logo": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
        "name": "HPA",
        "resource_types": [
          "model",
          "application"
        ],
        "source": "https://raw.githubusercontent.com/CellProfiling/HPA-model-zoo/master/manifest.bioimage.io.yaml",
        "splash_feature_list": [],
        "splash_subtitle": null,
        "splash_title": "The Human Protein Atlas",
        "tags": [
          "hpa"
        ]
      }
    ],
    "resource_types": [
      "model",
      "application",
      "dataset"
    ],
    "splash_feature_list": [
      "Integrate with Fiji, Ilastik, ImJoy",
      "Try model instantly with BioEngine",
      "Contribute your models via Github",
      "Link models to datasets and applications"
    ],
    "splash_subtitle": "Advanced AI models in one-click",
    "splash_title": "BioImage Model Zoo",
    "url_root": "https://raw.githubusercontent.com/bioimage-io/collection-bioimage-io/gh-pages"
  },
  "description": "BioImage.IO collection RDF",
  "documentation": "README.md",
  "format_version": "0.2.1",
  "git_repo": "https://github.com/bioimage-io/collection-bioimage-io",
  "icon": "https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/public/static/icons/android-chrome-384x384.png",
  "name": "BioImage.IO",
  "tags": [],
  "type": "collection",
  "version": "0.2.2"
}